{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77d98a4e-9418-4397-8b7a-8088621543bc",
   "metadata": {},
   "source": [
    "# Lista 2\n",
    "\n",
    "## Uczenie maszynowe i sztuczna inteligencja\n",
    "\n",
    "* [Naiwny klasyfikator bayesowski](https://en.wikipedia.org/wiki/Naive_Bayes_classifier) oraz [Naiwny wielomianowy klasyfikator bayesowski](https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Multinomial_naive_Bayes)\n",
    "* [Tokenizacja](https://en.wikipedia.org/wiki/Lexical_analysis#Tokenization)\n",
    "* [Multizbiór słów](https://en.wikipedia.org/wiki/Bag-of-words_model)\n",
    "* [N-gram](https://en.wikipedia.org/wiki/N-gram), [Bigram](https://en.wikipedia.org/wiki/Bigram), [Trigram](https://en.wikipedia.org/wiki/Trigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fd6799-47e0-46c6-b8e3-64a0cb60587c",
   "metadata": {},
   "source": [
    "## Wprowadzenie \n",
    "\n",
    "Spamowanie jest jednym z najprostszych ataków w przesyłaniu wiadomości e-mail. Użytkownicy często otrzymują irytujące wiadomości spamowe oraz złośliwe wiadomości phishingowe, subskrybując różne strony internetowe, produkty, usługi, katalogi, biuletyny informacyjne oraz inne rodzaje komunikacji elektronicznej. W niektórych przypadkach, spamowe wiadomości e-mail są generowane przez wirusy lub konie trojańskie rozsyłane masowo.\n",
    "\n",
    "Istnieje wiele rozwiązań do filtrowania spamu, takich jak techniki filtrowania na czarnej i białej liście, podejścia oparte na drzewach decyzyjnych, podejścia oparte na adresach e-mail oraz metody oparte na uczeniu maszynowym. Większość z nich opiera się głównie na analizie tekstu zawartości e-maila. W rezultacie rośnie zapotrzebowanie na skuteczne filtry antyspamowe, które automatycznie identyfikują i usuwają wiadomości spamowe lub ostrzegają użytkowników przed możliwymi wiadomościami spamowymi. Jednak spamerzy zawsze badają luki istniejących technik filtrowania spamu i wprowadzają nowy projekt do rozprzestrzeniania spamu w szerokim zakresie np. atak tokenizacji czasami wprowadza w błąd filtry antyspamowe, dodając dodatkowe spacje. Dlatego też treści e-maili muszą być strukturalizowane. Ponadto, pomimo posiadania najwyższej dokładności w wykrywaniu spamu za pomocą uczenia maszynowego, fałszywe pozytywy (False Positive, FP) stanowią problem z powodu jednorazowego wykrywania zagrożeń e-mailowych. Aby zaradzić problemom z fałszywymi pozytywami oraz zmianom w różnych projektach ataków, z tekstu usuwane są słowa kluczowe oraz inne niepożądane informacje przed dalszą analizą. Po wstępnym przetwarzaniu, te teksty przechodzą przez liczne metody ekstrakcji cech, takie jak word2vec, word n-gram, character n-gram oraz kombinacje n-gramów o zmiennych długościach. Różne techniki uczenia maszynowego, takie jak support vector machine (SVM), decision tree (DT), logistic regression (LR) oraz multinomial naıve bayes (MNB), są stosowany aby dokonać klasyfikacji e-maili.\n",
    "\n",
    "Na tej liste skoncentrujemy się tylko na metodzie naiwnego klasyfikatora bayesowskiego przedstawionego na wykładzie wraz z wersją [wielomianową](https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Multinomial_naive_Bayes).\n",
    "\n",
    "#### **Uwaga**\n",
    "\n",
    "**Wszystkie implementacje klasyfikatorów należy napisać samemu. Na tej liście nie korzystamy z implementacji klasyfikatorów istniejących w popularnych bibliotekach.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a550496e-1cac-4071-935a-6f92eec8afd7",
   "metadata": {},
   "source": [
    "\n",
    "# Klasyfikatory Naiwnego Bayesa (NB)\n",
    "\n",
    "W naszych eksperymentach po wstępnym przetworzeniu każda wiadomość jest ostatecznie reprezentowana jako wektor $\\mathbf{x}=(x_1, \\ldots , x_m)$, gdzie $x_1, \\ldots , x_m$ są wartościami atrybutów $X_1, \\ldots , X_m$ , a każdy atrybut dostarcza informacje o określonym tokenie wiadomości. W najprostszym przypadku wszystkie atrybuty są wartościami boolowskimi: $X_i = 1$, jeśli wiadomość zawiera dany token; w przeciwnym razie, $X_i = 0$. Alternatywnie, ich wartości mogą być częstotliwościami tokenów (TF), pokazującymi, ile razy odpowiadający token występuje w wiadomości. Atrybuty z wartościami TF przenoszą więcej informacji niż atrybuty boolowskie.\n",
    "\n",
    "Z twierdzenia Bayesa wynika, że prawdopodobieństwo, że wiadomość o wektorze $\\mathbf{x} = (x_1, \\ldots, x_m)$ należy do kategorii $c$, wynosi: \n",
    "\n",
    "$$\n",
    "p(c | \\mathbf{x}) = \\frac{p(c) \\cdot p(\\mathbf{x} | c)}{p(\\mathbf{x})}\n",
    "$$\n",
    "\n",
    "Ponieważ mianownik nie zależy od kategorii, klasyfikator NB klasyfikuje każdą wiadomość do kategorii, która maksymalizuje $p(c) \\cdot p(\\mathbf{x} | c)$. W przypadku filtrowania spamu oznacza to klasyfikowanie wiadomości jako spamu, gdy: \n",
    "\n",
    "$$\n",
    "\\frac{p(c_s) \\cdot p(\\mathbf{x} | c_s)}{p(c_s) \\cdot p(\\mathbf{x} | c_s) + p(c_h) \\cdot p(\\mathbf{x} | c_h)} > T\n",
    "$$\n",
    "\n",
    "gdzie $T = 0.5$, a $c_h$ i $c_s$ oznaczają kategorie ham i spam. Zmieniając $T$, można zdecydować się na więcej prawdziwych negatywów (poprawnie sklasyfikowane wiadomości ham) kosztem mniej prawdziwych pozytywów (poprawnie sklasyfikowane wiadomości spam), lub odwrotnie. Prawdopodobieństwa a priori $p(c)$ są zwykle szacowane przez podzielenie liczby treningowych wiadomości kategorii $c$ przez łączną liczbę treningowych wiadomości. Prawdopodobieństwa $p(\\mathbf{x} | c)$ są szacowane w różny sposób w każdej wersji NB - patrz wykład.\n",
    "\n",
    "# Naiwny klasyfikator bayesowski wielomianowy (MNB)\n",
    "\n",
    "Klasyfikator [wielomianowy](https://en.wikipedia.org/wiki/Multinomial_distribution) bayesowski z atrybutami TF traktuje każdą wiadomość $d$ jako [multizbiór]((https://en.wikipedia.org/wiki/Bag-of-words_model)) tokenów, zawierający każdy token $t_i$ tyle razy, ile występuje w $d$. Dlatego $d$ można przedstawić jako $\\mathbf{x} = (x_1, ..., x_m)$, gdzie każde $x_i$ to teraz liczba wystąpień $t_i$ w $d$. Ponadto, każda wiadomość $d$ z kategorii $c$ jest postrzegana jako wynik niezależnego wyboru $|d|$ tokenów z $F=\\{t_1,\\ldots,t_m\\}$ z powtórzeniami, z prawdopodobieństwem $p(t_i | c)$ dla każdego $t_i$. Wówczas $p(\\mathbf{x} | c)$ jest rozkładem wielomianowym:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{x} \\mid c) = p(|d|) \\cdot |d|! \\cdot \\prod_{i=1}^{d} \\frac{p(t_i \\mid c)^{x_i}}{x_i !}\n",
    "$$\n",
    "\n",
    "gdzie zakładamy, że $|d|$ nie zależy od kategorii $c$. Jest to dodatkowe uproszczające założenie, które jest bardziej dyskusyjne w filtrowaniu spamu. Na przykład, prawdopodobieństwo otrzymania bardzo długiej wiadomości spamowej wydaje się mniejsze niż prawdopodobieństwo otrzymania równie długiej wiadomości ham. Kryterium klasyfikacji wiadomości jako spamu staje się:\n",
    "\n",
    "$$\n",
    "\\frac{p(c_s) \\cdot \\prod_{i=1}^{m} p(t_i \\mid c_s)^{x_i}}{p(c_s)\\cdot\\prod_{i=1}^{m} p(t_i \\mid c_s)^{x_i} + p(c_h)\\cdot\\prod_{i=1}^{m} p(t_i \\mid c_h)^{x_i}}  > T\n",
    "$$\n",
    "\n",
    "gdzie każde $p(t_i | c)$ jest szacowane jako:\n",
    "\n",
    "$$\n",
    "p(t \\mid c) = \\frac{\\alpha + N_{t,c}}{\\alpha \\cdot m + N_c}\n",
    "$$\n",
    "gdzie $N_{t,c}$ to liczba wystąpień tokena $t$ w treningowych wiadomościach kategorii $c$, podczas gdy $N_c = \\sum_{i=1}^{m} N_{t_i,c}$ to łączna liczba wiadomości treningowych kategorii $c$. W praktyce dodaje się jeszcze parametr $\\alpha$ który reprezentuje wygładzenie (smoothing) i rozwiązuje problem zerowego prawdopodobieństwa, patrz [http://www.paulgraham.com/spam.html](http://www.paulgraham.com/spam.html) (np. $\\alpha=1$).\n",
    "\n",
    "\n",
    "### Przykładowe dane wielomianowe\n",
    "\n",
    "Zatem każda wiadomość $d$  składa się z różnych tokenów $t_i$, a każde z tych $t_i$ należy do słownika $\\mathcal{V}$. Jeśli $\\mathcal{V}$ zawiera np. $8$ tokenów, $t_1,t_2,...,t_8$, a wiadomość to: $t_1 t_2 t_2 t_6 t_3 t_2 t_8$, reprezentacja tej wiadomości będzie następująca:\n",
    "\n",
    "| |$t_1$|$t_2$|$t_3$|$t_4$|$t_5$|$t_6$|$t_7$|$t_8$|\n",
    "|---|---|---|---|---|---|---|---|---|\n",
    "|$\\mathbf{x}$| 1|3 |1 | 0| 0|1 | 0|1 |\n",
    "\n",
    "Po dodaniu kilku innych losowych wiadomości, zbiór danych wygląda tak:\n",
    "\n",
    "|$t_1$|$t_2$|$t_3$|$t_4$|$t_5$|$t_6$|$t_7$|$t_8$|$c$|\n",
    "|---|---|---|---|---|---|---|---|---|\n",
    "| 1|3 |1 | 0| 0|1 | 0|1 | spam|\n",
    "| 1|0 |0 | 0| 1|1 | 1|3 | ham|\n",
    "| 0|0 |0 | 0| 0|2 | 1|2 | spam|\n",
    "\n",
    "Przyjmując klasy ($1$-spam,$0$-ham) mamy $c = [1,0,1]$. Teraz, porównując z równaniem powyżej,\n",
    "\n",
    "- $N_{t_i,c}$ to liczba wystąpień cechy $t_i$ w każdej unikalnej klasie $c$. Na przykład, dla $c=1$, $N_{t_1,c}=1, N_{t_6,c}=3$\n",
    "- $N_c$ to całkowita liczba wystąpień wszystkich cech w każdej unikalnej klasie $c$. Na przykład, dla $c=1$, $N_c=12$\n",
    "- $m=8$ to całkowita liczba cech\n",
    "- $\\alpha=1$ jest znany jako parametr wygładzania. Jest on potrzebny do problemu zerowego prawdopodobieństwa (patrz [http://www.paulgraham.com/spam.html](http://www.paulgraham.com/spam.html))\n",
    "\n",
    "# Niedomiar zmiennoprzecinkowy (floating point underflow)\n",
    "\n",
    "Aby uniknąć problemu niedomiaru zmiennoprzecinkowego, mnożenie zbioru małych prawdopodobieństw, czyli po prostu iloczyn stanie się zbyt mały, aby go reprezentować i zostanie zastąpiony przez 0. Zamiast obliczać\n",
    "$$\n",
    "P(c) \\prod_{i=1}^m P(t_i | c)\n",
    "$$\n",
    "co może spowodować niedomiar, rozważmy obliczenie logarytmu tego wyrażenia,\n",
    "$$\n",
    "\\log\\left(P(c) \\prod_{i=1}^m P(t_i | c)\\right)\n",
    "$$\n",
    "co równoważnie można zapisać jako\n",
    "$$\n",
    "\\log(P(c))+ \\sum_{i=1}^m \\log(P(t_i | c))\n",
    "$$\n",
    "Następnie zauważ, że jeśli\n",
    "$$\n",
    "\\log(P(c_s))+ \\sum_{i=1}^m \\log(P(t_i | c_s)) > \\log(P(c_h))+ \\sum_{i=1}^m \\log(P(t_i | c_h))\n",
    "$$\n",
    "wtedy, ponieważ $\\log(x) > \\log(y)$ iff $x > y$, to\n",
    "$$\n",
    "P(c_s) \\prod_{i=1}^m P(t_i | c_s) > P(c_h) \\prod_{i=1}^m P(t_i | c_h)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ff1e5a-8599-412a-9494-45699a65a2fb",
   "metadata": {},
   "source": [
    "## Zadanie 1 (10pt)\n",
    "\n",
    "### Klasyfikator oparty na algorytmie NB\n",
    "\n",
    "#### Cel:\n",
    "Zbudować prosty klasyfikator spamu oparty na NB, który będzie w stanie wykryć i odfiltrować niechciane wiadomości e-mail.\n",
    "\n",
    "#### Opis:\n",
    "1. Zbierz zbiór danych zawierający etykiety (spam/nie-spam) oraz treść wiadomości e-mail np. [Enron-Spam](http://nlp.cs.aueb.gr/software_and_datasets/Enron-Spam/index.html) lub [SMS Spam Collection](https://archive.ics.uci.edu/dataset/228/sms+spam+collection) lub [E-mail Spam](https://www.kaggle.com/datasets/balaka18/email-spam-classification-dataset-csv) lub ...\n",
    "2. Przygotuj dane poprzez tokenizację słów i usuń zbędne znaki interpunkcyjne.\n",
    "3. Zaimplementuj NB, który będzie w stanie klasyfikować wiadomości jako spam lub nie-spam na podstawie występujących słów.\n",
    "4. Podziel dane na zbiór treningowy i testowy (np. 70% do treningu, 30% do testu).\n",
    "5. Wytrenuj klasyfikator NB na danych treningowych.\n",
    "6. Przetestuj klasyfikator na danych testowych i oceniaj jego skuteczność przy użyciu metryk: [precision i recall](https://en.wikipedia.org/wiki/Precision_and_recall), [f1-score](https://en.wikipedia.org/wiki/F-score) oraz [accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision).\n",
    "7. Dokonaj analizy wyników i przedstaw wnioski.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3db03424-f98e-4b03-8cb3-cbb1cb5d4935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "sms_spam = pd.read_csv(\n",
    "    \"SMSSpamCollection\", sep=\"\\t\", header=None, names=[\"Label\", \"SMS\"]\n",
    ")\n",
    "\n",
    "print(sms_spam.shape)\n",
    "sms_spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cc39fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3900, 2)\n",
      "(1672, 2)\n"
     ]
    }
   ],
   "source": [
    "# Randomize the dataset\n",
    "data_randomized = sms_spam.sample(frac=1, random_state=42069)\n",
    "\n",
    "# Calculate index for split\n",
    "training_test_index = round(len(data_randomized) * 0.7)\n",
    "\n",
    "# Training/Test split\n",
    "training_set = data_randomized[:training_test_index].reset_index(drop=True)\n",
    "test_set = data_randomized[training_test_index:].reset_index(drop=True)\n",
    "\n",
    "print(training_set.shape)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95a7b79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before:\n",
      "0    Probably not, I'm almost out of gas and I get ...\n",
      "1    Goodmorning, today i am late for 2hrs. Because...\n",
      "2                  Vikky, come around  &lt;TIME&gt; ..\n",
      "3    Today is ACCEPT DAY..U Accept me as? Brother S...\n",
      "4    Can u look 4 me in da lib i got stuff havent f...\n",
      "Name: SMS, dtype: object\n",
      "after:\n",
      "0    probably not  i m almost out of gas and i get ...\n",
      "1    goodmorning  today i am late for 2hrs  because...\n",
      "2                  vikky  come around   lt time gt    \n",
      "3    today is accept day  u accept me as  brother s...\n",
      "4    can u look 4 me in da lib i got stuff havent f...\n",
      "Name: SMS, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Clean the data\n",
    "print(\"before:\")\n",
    "print(training_set[\"SMS\"].head())\n",
    "\n",
    "# Remove all punctuation and change to lowercase\n",
    "training_set[\"SMS\"] = training_set[\"SMS\"].map(lambda x: re.sub('\\W', ' ', x))\n",
    "training_set[\"SMS\"] = training_set[\"SMS\"].str.lower()\n",
    "\n",
    "print(\"after:\")\n",
    "print(training_set[\"SMS\"].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea0a9ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set[\"SMS\"] = training_set[\"SMS\"].str.split() # split the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fd3c3b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7226"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = set()\n",
    "\n",
    "for sms in training_set[\"SMS\"]:\n",
    "    for word in sms:\n",
    "        vocabulary.add(word)\n",
    "\n",
    "vocabulary = list(vocabulary)\n",
    "vocabulary.sort()\n",
    "\n",
    "len(vocabulary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f13b1da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>0121</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>...</th>\n",
       "      <th>zeros</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zyada</th>\n",
       "      <th>èn</th>\n",
       "      <th>é</th>\n",
       "      <th>ü</th>\n",
       "      <th>〨ud</th>\n",
       "      <th>鈥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[probably, not, i, m, almost, out, of, gas, an...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[goodmorning, today, i, am, late, for, 2hrs, b...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[vikky, come, around, lt, time, gt]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[today, is, accept, day, u, accept, me, as, br...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[can, u, look, 4, me, in, da, lib, i, got, stu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7228 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  0  00  000  \\\n",
       "0   ham  [probably, not, i, m, almost, out, of, gas, an...  0   0    0   \n",
       "1   ham  [goodmorning, today, i, am, late, for, 2hrs, b...  0   0    0   \n",
       "2   ham                [vikky, come, around, lt, time, gt]  0   0    0   \n",
       "3   ham  [today, is, accept, day, u, accept, me, as, br...  0   0    0   \n",
       "4   ham  [can, u, look, 4, me, in, da, lib, i, got, stu...  0   0    0   \n",
       "\n",
       "   000pes  008704050406  0089  0121  01223585334  ...  zeros  zindgi  zoe  \\\n",
       "0       0             0     0     0            0  ...      0       0    0   \n",
       "1       0             0     0     0            0  ...      0       0    0   \n",
       "2       0             0     0     0            0  ...      0       0    0   \n",
       "3       0             0     0     0            0  ...      0       0    0   \n",
       "4       0             0     0     0            0  ...      0       0    0   \n",
       "\n",
       "   zoom  zyada  èn  é  ü  〨ud  鈥  \n",
       "0     0      0   0  0  0    0  0  \n",
       "1     0      0   0  0  0    0  0  \n",
       "2     0      0   0  0  0    0  0  \n",
       "3     0      0   0  0  0    0  0  \n",
       "4     0      0   0  0  0    0  0  \n",
       "\n",
       "[5 rows x 7228 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize the dictionary\n",
    "words_per_sms = {\n",
    "    unique_word: [0] * len(training_set[\"SMS\"]) for unique_word in vocabulary\n",
    "}\n",
    "\n",
    "for index, sms in enumerate(training_set[\"SMS\"]):\n",
    "    for word in sms:\n",
    "        words_per_sms[word][index] = 1\n",
    "\n",
    "words = pd.DataFrame(words_per_sms)\n",
    "\n",
    "training_set_clean = pd.concat([training_set, words], axis=1)\n",
    "training_set_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52c02cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate spam and ham messages first\n",
    "spam_messages = training_set_clean[training_set_clean[\"Label\"] == \"spam\"]\n",
    "ham_messages = training_set_clean[training_set_clean[\"Label\"] == \"ham\"]\n",
    "\n",
    "# P(Spam) and P(Ham)\n",
    "p_spam = len(spam_messages) / len(training_set_clean)\n",
    "p_ham = len(ham_messages) / len(training_set_clean)\n",
    "\n",
    "# N_Spam\n",
    "n_words_per_spam_message = spam_messages[\"SMS\"].apply(len)\n",
    "n_spam = n_words_per_spam_message.sum()\n",
    "\n",
    "# N_Ham\n",
    "n_words_per_ham_message = ham_messages[\"SMS\"].apply(len)\n",
    "n_ham = n_words_per_ham_message.sum()\n",
    "\n",
    "# N_Vocabulary\n",
    "n_vocabulary = len(vocabulary)\n",
    "\n",
    "# Laplace smoothing\n",
    "alpha = 1\n",
    "\n",
    "# Initiate parameters\n",
    "parameters_spam = {unique_word: 0 for unique_word in vocabulary}\n",
    "parameters_ham = {unique_word: 0 for unique_word in vocabulary}\n",
    "\n",
    "# Calculate parameters (train the model)\n",
    "for word in vocabulary:\n",
    "    n_word_given_spam = spam_messages[word].sum()\n",
    "    p_word_given_spam = (n_word_given_spam + alpha) / (n_spam + alpha * n_vocabulary)\n",
    "    parameters_spam[word] = p_word_given_spam\n",
    "\n",
    "    n_word_given_ham = ham_messages[word].sum()\n",
    "    p_word_given_ham = (n_word_given_ham + alpha) / (n_ham + alpha * n_vocabulary)\n",
    "    parameters_ham[word] = p_word_given_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d3cda5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as m\n",
    "\n",
    "def classify_test_set(message):\n",
    "    message = re.sub(\"\\W\", \" \", message)\n",
    "    message = message.lower().split()\n",
    "    message = list(set(message))\n",
    "\n",
    "    p_spam_given_message = m.log(p_spam)\n",
    "    p_ham_given_message = m.log(p_ham)\n",
    "\n",
    "    for word in message:\n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message += m.log(parameters_spam[word])\n",
    "\n",
    "        if word in parameters_ham:\n",
    "            p_ham_given_message += m.log(parameters_ham[word])\n",
    "\n",
    "    if p_ham_given_message >= p_spam_given_message:\n",
    "        return \"ham\"\n",
    "    else:\n",
    "        return \"spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d50c5de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh, i will get paid. The most outstanding one ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ha ha ha good joke. Girls are situation seekers.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Okie...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Think + da. You wil do.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Were somewhere on Fredericksburg</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham  Oh, i will get paid. The most outstanding one ...       ham\n",
       "1   ham   Ha ha ha good joke. Girls are situation seekers.       ham\n",
       "2   ham                                            Okie...       ham\n",
       "3   ham                            Think + da. You wil do.       ham\n",
       "4   ham                   Were somewhere on Fredericksburg       ham"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[\"predicted\"] = test_set[\"SMS\"].apply(classify_test_set)\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd7c77d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 1645\n",
      "Incorrect: 27\n",
      "Accuracy: 0.9838516746411483\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy\n",
    "correct = 0\n",
    "total = test_set.shape[0]\n",
    "\n",
    "for row in test_set.iterrows():\n",
    "    row = row[1]\n",
    "    if row[\"Label\"] == row[\"predicted\"]:\n",
    "        correct += 1\n",
    "\n",
    "print(\"Correct:\", correct)\n",
    "print(\"Incorrect:\", total - correct)\n",
    "print(\"Accuracy:\", correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c877b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9734513274336283\n",
      "Recall: 0.9128630705394191\n"
     ]
    }
   ],
   "source": [
    "# Calcuate precision and recall\n",
    "true_positives = len(test_set[(test_set[\"Label\"] == \"spam\") & (test_set[\"predicted\"] == \"spam\")])\n",
    "true_negatives = len(test_set[(test_set[\"Label\"] == \"ham\") & (test_set[\"predicted\"] == \"ham\")])\n",
    "false_positives = len(test_set[(test_set[\"Label\"] == \"ham\") & (test_set[\"predicted\"] == \"spam\")])\n",
    "false_negatives = len(test_set[(test_set[\"Label\"] == \"spam\") & (test_set[\"predicted\"] == \"ham\")])\n",
    "\n",
    "precision = true_positives / (true_positives + false_positives) # true positives / total predicted positives\n",
    "recall = true_positives / (true_positives + false_negatives) # true positives / total actual positives\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7779c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9421841541755888\n"
     ]
    }
   ],
   "source": [
    "# Calculate the F1 score\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a933bb-c803-4e52-a562-e2a47944fb5f",
   "metadata": {},
   "source": [
    "## Zadanie 2 (15pt)\n",
    "\n",
    "### Klasyfikator oparty na n-gramach MNB\n",
    "\n",
    "#### Cel:\n",
    "Zbudować klasyfikator spamu, wykorzystując n-gramy w połączeniu MNB, aby poprawić skuteczność klasyficji wiadomości e-mail.\n",
    "\n",
    "#### Opis:\n",
    "1. Zbierz zbiór danych zawierający etykiety (spam/nie-spam) oraz treść wiadomości e-mail np. [Enron-Spam](http://nlp.cs.aueb.gr/software_and_datasets/Enron-Spam/index.html) lub [SMS Spam Collection](https://archive.ics.uci.edu/dataset/228/sms+spam+collection) lub [E-mail Spam](https://www.kaggle.com/datasets/balaka18/email-spam-classification-dataset-csv) lub ...\n",
    "2. Przygotuj dane poprzez tworzenie n-gramów z treści wiadomości e-mail tzn. unigramy, bigramy, trigramy.\n",
    "3. Zaimplementuj MNB, który będzie w stanie klasyfikować wiadomości jako spam lub nie-spam, wykorzystując n-gramy jako cechy.\n",
    "4. Podziel dane na zbiór treningowy i testowy (np. 70% do treningu, 30% do testu).\n",
    "5. Wytrenuj klasyfikator MNB na danych treningowych, wykorzystując n-gramy jako cechy.\n",
    "6. Przetestuj klasyfikator na danych testowych i oceniaj jego skuteczność przy użyciu metryk: [precision i recall](https://en.wikipedia.org/wiki/Precision_and_recall), [f1-score](https://en.wikipedia.org/wiki/F-score) oraz [accuracy](https://en.wikipedia.org/wiki/Accuracy_and_precision).\n",
    "7. Dokonaj analizy wyników i porównaj je z wynikami klasyfikatora opartego na słowach.\n",
    "8. Przedstaw wnioski dotyczące skuteczności klasyfikatora opartego na n-gramach oraz wpływu różnych typów n-gramów na skuteczność klasyfikacji.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b2135aa-3e93-4bd9-8d6d-467f14e29f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n",
      "(3900, 2)\n",
      "(1672, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>n-gram</th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>0121</th>\n",
       "      <th>...</th>\n",
       "      <th>zeros</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zyada</th>\n",
       "      <th>èn</th>\n",
       "      <th>é</th>\n",
       "      <th>ü</th>\n",
       "      <th>〨ud</th>\n",
       "      <th>鈥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Probably not, I'm almost out of gas and I get ...</td>\n",
       "      <td>[probably, not, i, m, almost, out, of, gas, an...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Goodmorning, today i am late for 2hrs. Because...</td>\n",
       "      <td>[goodmorning, today, i, am, late, for, 2hrs, b...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Vikky, come around  &amp;lt;TIME&amp;gt; ..</td>\n",
       "      <td>[vikky, come, around, lt, time, gt]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Today is ACCEPT DAY..U Accept me as? Brother S...</td>\n",
       "      <td>[today, is, accept, day, u, accept, me, as, br...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Can u look 4 me in da lib i got stuff havent f...</td>\n",
       "      <td>[can, u, look, 4, me, in, da, lib, i, got, stu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7229 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  \\\n",
       "0   ham  Probably not, I'm almost out of gas and I get ...   \n",
       "1   ham  Goodmorning, today i am late for 2hrs. Because...   \n",
       "2   ham                Vikky, come around  &lt;TIME&gt; ..   \n",
       "3   ham  Today is ACCEPT DAY..U Accept me as? Brother S...   \n",
       "4   ham  Can u look 4 me in da lib i got stuff havent f...   \n",
       "\n",
       "                                              n-gram  0  00  000  000pes  \\\n",
       "0  [probably, not, i, m, almost, out, of, gas, an...  0   0    0       0   \n",
       "1  [goodmorning, today, i, am, late, for, 2hrs, b...  0   0    0       0   \n",
       "2                [vikky, come, around, lt, time, gt]  0   0    0       0   \n",
       "3  [today, is, accept, day, u, accept, me, as, br...  0   0    0       0   \n",
       "4  [can, u, look, 4, me, in, da, lib, i, got, stu...  0   0    0       0   \n",
       "\n",
       "   008704050406  0089  0121  ...  zeros  zindgi  zoe  zoom  zyada  èn  é  ü  \\\n",
       "0             0     0     0  ...      0       0    0     0      0   0  0  0   \n",
       "1             0     0     0  ...      0       0    0     0      0   0  0  0   \n",
       "2             0     0     0  ...      0       0    0     0      0   0  0  0   \n",
       "3             0     0     0  ...      0       0    0     0      0   0  0  0   \n",
       "4             0     0     0  ...      0       0    0     0      0   0  0  0   \n",
       "\n",
       "   〨ud  鈥  \n",
       "0    0  0  \n",
       "1    0  0  \n",
       "2    0  0  \n",
       "3    0  0  \n",
       "4    0  0  \n",
       "\n",
       "[5 rows x 7229 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "\n",
    "sms_spam = pd.read_csv(\n",
    "    \"SMSSpamCollection\", sep=\"\\t\", header=None, names=[\"Label\", \"SMS\"]\n",
    ")\n",
    "\n",
    "print(sms_spam.shape)\n",
    "sms_spam.head()\n",
    "\n",
    "# Randomize the dataset\n",
    "data_randomized = sms_spam.sample(frac=1, random_state=42069)\n",
    "\n",
    "# Calculate index for split\n",
    "training_test_index = round(len(data_randomized) * 0.7)\n",
    "\n",
    "# Training/Test split\n",
    "training_set = data_randomized[:training_test_index].reset_index(drop=True)\n",
    "test_set = data_randomized[training_test_index:].reset_index(drop=True)\n",
    "\n",
    "print(training_set.shape)\n",
    "print(test_set.shape)\n",
    "\n",
    "\n",
    "# create n-grams from the messages\n",
    "def create_ngrams(message, n):\n",
    "    message = re.sub(\"\\W\", \" \", message)\n",
    "    message = message.lower().split()\n",
    "    ngrams = []\n",
    "    for i in range(len(message) - n + 1):\n",
    "        ngrams.append(\" \".join(message[i:i+n]))\n",
    "    return ngrams\n",
    "\n",
    "# create 1-gram, 2-gram, and 3-gram and add to the training set\n",
    "training_sets = []\n",
    "\n",
    "for n in range(1, 4):\n",
    "    training_set_copy = training_set.copy()\n",
    "    training_set_copy[\"n-gram\"] = training_set_copy[\"SMS\"].apply(create_ngrams, n=n)\n",
    "    training_sets.append(training_set_copy)\n",
    "\n",
    "# create a vocabulary for each n-gram\n",
    "vocabulary = [set() for n in range(1, 4)]\n",
    "\n",
    "for n in range(1, 4):\n",
    "    for message in training_sets[n - 1][\"n-gram\"]:\n",
    "        for ngram in message:\n",
    "            vocabulary[n - 1].add(ngram)\n",
    "\n",
    "vocabulary = [sorted(list(vocabulary[n - 1])) for n in range(1, 4)]\n",
    "\n",
    "# count the frequency of each n-gram\n",
    "ngram_counts = {n: {ngram: [0] * len(training_set) for ngram in vocabulary[n - 1]} for n in range(1, 4)}\n",
    "\n",
    "for n in range(1, 4):\n",
    "    for index, message in enumerate(training_sets[n - 1][\"n-gram\"]):\n",
    "        for ngram in message:\n",
    "            ngram_counts[n][ngram][index] += 1\n",
    "\n",
    "# create a dataframe for each n-gram\n",
    "ngram_dataframes = {n: pd.DataFrame(ngram_counts[n]) for n in range(1, 4)}\n",
    "\n",
    "# concatenate the n-gram dataframes with the training set\n",
    "training_sets_clean = []\n",
    "for n in range(1, 4):\n",
    "    training_set_clean = pd.concat([training_sets[n - 1], ngram_dataframes[n]], axis=1)\n",
    "    training_sets_clean.append(training_set_clean)\n",
    "\n",
    "training_sets_clean[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d93376d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>n-gram</th>\n",
       "      <th>0 for</th>\n",
       "      <th>0 key</th>\n",
       "      <th>00 per</th>\n",
       "      <th>00 sub</th>\n",
       "      <th>00 subs</th>\n",
       "      <th>000 bonus</th>\n",
       "      <th>000 cash</th>\n",
       "      <th>...</th>\n",
       "      <th>ü v</th>\n",
       "      <th>ü wait</th>\n",
       "      <th>ü wan</th>\n",
       "      <th>ü willing</th>\n",
       "      <th>ü wkg</th>\n",
       "      <th>ü yet</th>\n",
       "      <th>ü yup</th>\n",
       "      <th>ü ü</th>\n",
       "      <th>〨ud evening</th>\n",
       "      <th>鈥 〨ud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Probably not, I'm almost out of gas and I get ...</td>\n",
       "      <td>[probably not, not i, i m, m almost, almost ou...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Goodmorning, today i am late for 2hrs. Because...</td>\n",
       "      <td>[goodmorning today, today i, i am, am late, la...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Vikky, come around  &amp;lt;TIME&amp;gt; ..</td>\n",
       "      <td>[vikky come, come around, around lt, lt time, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Today is ACCEPT DAY..U Accept me as? Brother S...</td>\n",
       "      <td>[today is, is accept, accept day, day u, u acc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Can u look 4 me in da lib i got stuff havent f...</td>\n",
       "      <td>[can u, u look, look 4, 4 me, me in, in da, da...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32750 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  \\\n",
       "0   ham  Probably not, I'm almost out of gas and I get ...   \n",
       "1   ham  Goodmorning, today i am late for 2hrs. Because...   \n",
       "2   ham                Vikky, come around  &lt;TIME&gt; ..   \n",
       "3   ham  Today is ACCEPT DAY..U Accept me as? Brother S...   \n",
       "4   ham  Can u look 4 me in da lib i got stuff havent f...   \n",
       "\n",
       "                                              n-gram  0 for  0 key  00 per  \\\n",
       "0  [probably not, not i, i m, m almost, almost ou...      0      0       0   \n",
       "1  [goodmorning today, today i, i am, am late, la...      0      0       0   \n",
       "2  [vikky come, come around, around lt, lt time, ...      0      0       0   \n",
       "3  [today is, is accept, accept day, day u, u acc...      0      0       0   \n",
       "4  [can u, u look, look 4, 4 me, me in, in da, da...      0      0       0   \n",
       "\n",
       "   00 sub  00 subs  000 bonus  000 cash  ...  ü v  ü wait  ü wan  ü willing  \\\n",
       "0       0        0          0         0  ...    0       0      0          0   \n",
       "1       0        0          0         0  ...    0       0      0          0   \n",
       "2       0        0          0         0  ...    0       0      0          0   \n",
       "3       0        0          0         0  ...    0       0      0          0   \n",
       "4       0        0          0         0  ...    0       0      0          0   \n",
       "\n",
       "   ü wkg  ü yet  ü yup  ü ü  〨ud evening  鈥 〨ud  \n",
       "0      0      0      0    0            0      0  \n",
       "1      0      0      0    0            0      0  \n",
       "2      0      0      0    0            0      0  \n",
       "3      0      0      0    0            0      0  \n",
       "4      0      0      0    0            0      0  \n",
       "\n",
       "[5 rows x 32750 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_sets_clean[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2796c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>n-gram</th>\n",
       "      <th>0 for games</th>\n",
       "      <th>0 key for</th>\n",
       "      <th>00 sub 16</th>\n",
       "      <th>00 subs 16</th>\n",
       "      <th>000 bonus caller</th>\n",
       "      <th>000 cash await</th>\n",
       "      <th>000 homeowners tenants</th>\n",
       "      <th>...</th>\n",
       "      <th>ü wan call</th>\n",
       "      <th>ü wan come</th>\n",
       "      <th>ü wan meet</th>\n",
       "      <th>ü wan to</th>\n",
       "      <th>ü willing to</th>\n",
       "      <th>ü wkg on</th>\n",
       "      <th>ü yet right</th>\n",
       "      <th>ü yup i</th>\n",
       "      <th>ü ü wan</th>\n",
       "      <th>鈥 〨ud evening</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Probably not, I'm almost out of gas and I get ...</td>\n",
       "      <td>[probably not i, not i m, i m almost, m almost...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Goodmorning, today i am late for 2hrs. Because...</td>\n",
       "      <td>[goodmorning today i, today i am, i am late, a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Vikky, come around  &amp;lt;TIME&amp;gt; ..</td>\n",
       "      <td>[vikky come around, come around lt, around lt ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Today is ACCEPT DAY..U Accept me as? Brother S...</td>\n",
       "      <td>[today is accept, is accept day, accept day u,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Can u look 4 me in da lib i got stuff havent f...</td>\n",
       "      <td>[can u look, u look 4, look 4 me, 4 me in, me ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43896 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  \\\n",
       "0   ham  Probably not, I'm almost out of gas and I get ...   \n",
       "1   ham  Goodmorning, today i am late for 2hrs. Because...   \n",
       "2   ham                Vikky, come around  &lt;TIME&gt; ..   \n",
       "3   ham  Today is ACCEPT DAY..U Accept me as? Brother S...   \n",
       "4   ham  Can u look 4 me in da lib i got stuff havent f...   \n",
       "\n",
       "                                              n-gram  0 for games  0 key for  \\\n",
       "0  [probably not i, not i m, i m almost, m almost...            0          0   \n",
       "1  [goodmorning today i, today i am, i am late, a...            0          0   \n",
       "2  [vikky come around, come around lt, around lt ...            0          0   \n",
       "3  [today is accept, is accept day, accept day u,...            0          0   \n",
       "4  [can u look, u look 4, look 4 me, 4 me in, me ...            0          0   \n",
       "\n",
       "   00 sub 16  00 subs 16  000 bonus caller  000 cash await  \\\n",
       "0          0           0                 0               0   \n",
       "1          0           0                 0               0   \n",
       "2          0           0                 0               0   \n",
       "3          0           0                 0               0   \n",
       "4          0           0                 0               0   \n",
       "\n",
       "   000 homeowners tenants  ...  ü wan call  ü wan come  ü wan meet  ü wan to  \\\n",
       "0                       0  ...           0           0           0         0   \n",
       "1                       0  ...           0           0           0         0   \n",
       "2                       0  ...           0           0           0         0   \n",
       "3                       0  ...           0           0           0         0   \n",
       "4                       0  ...           0           0           0         0   \n",
       "\n",
       "   ü willing to  ü wkg on  ü yet right  ü yup i  ü ü wan  鈥 〨ud evening  \n",
       "0             0         0            0        0        0              0  \n",
       "1             0         0            0        0        0              0  \n",
       "2             0         0            0        0        0              0  \n",
       "3             0         0            0        0        0              0  \n",
       "4             0         0            0        0        0              0  \n",
       "\n",
       "[5 rows x 43896 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_sets_clean[2].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cc07309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate spam and ham messages first\n",
    "spam_messages = training_sets_clean[0][training_sets_clean[0][\"Label\"] == \"spam\"]\n",
    "ham_messages = training_sets_clean[0][training_sets_clean[0][\"Label\"] == \"ham\"]\n",
    "\n",
    "# P(Spam) and P(Ham)\n",
    "p_spam = len(spam_messages) / len(training_sets_clean[0])\n",
    "p_ham = len(ham_messages) / len(training_sets_clean[0])\n",
    "\n",
    "# Initiate parameters\n",
    "parameters_spam = [\n",
    "    {unique_word: 0 for unique_word in vocabulary[n - 1]} for n in range(1, 4)\n",
    "]\n",
    "parameters_ham = [{unique_word: 0 for unique_word in vocabulary[n - 1]} for n in range(1, 4)]\n",
    "\n",
    "for n in range(1, 4):\n",
    "    # Isolate spam and ham messages first\n",
    "    spam_messages = training_sets_clean[n - 1][training_sets_clean[n - 1][\"Label\"] == \"spam\"]\n",
    "    ham_messages = training_sets_clean[n - 1][training_sets_clean[n - 1][\"Label\"] == \"ham\"]\n",
    "\n",
    "    # N_Spam for n-gram\n",
    "    n_words_per_spam_message = spam_messages[\"n-gram\"].apply(len)\n",
    "    n_spam = n_words_per_spam_message.sum()\n",
    "\n",
    "    # N_Ham\n",
    "    n_words_per_ham_message = ham_messages[\"n-gram\"].apply(len)\n",
    "    n_ham = n_words_per_ham_message.sum()\n",
    "\n",
    "    # N_Vocabulary\n",
    "    n_vocabulary = len(vocabulary[n - 1])\n",
    "\n",
    "    # Laplace smoothing\n",
    "    alpha = 1\n",
    "\n",
    "    # Calculate parameters (train the model)\n",
    "    for word in vocabulary[n - 1]:\n",
    "        n_word_given_spam = spam_messages[word].sum()\n",
    "        p_word_given_spam = (n_word_given_spam + alpha) / (n_spam + alpha * n_vocabulary)\n",
    "        parameters_spam[n - 1][word] = p_word_given_spam\n",
    "\n",
    "        n_word_given_ham = ham_messages[word].sum()\n",
    "        p_word_given_ham = (n_word_given_ham + alpha) / (n_ham + alpha * n_vocabulary)\n",
    "        parameters_ham[n - 1][word] = p_word_given_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94cd66f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test_set(message, n):\n",
    "    # tokenize the message into n-grams\n",
    "    message = create_ngrams(message, n)\n",
    "\n",
    "    p_spam_given_message = m.log(p_spam)\n",
    "    p_ham_given_message = m.log(p_ham)\n",
    "\n",
    "    for word in message:\n",
    "        if word in parameters_spam[n - 1]:\n",
    "            p_spam_given_message += m.log(parameters_spam[n - 1][word])\n",
    "\n",
    "        if word in parameters_ham[n - 1]:\n",
    "            p_ham_given_message += m.log(parameters_ham[n - 1][word])\n",
    "\n",
    "    if p_ham_given_message >= p_spam_given_message:\n",
    "        return \"ham\"\n",
    "    else:\n",
    "        return \"spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33b6d2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 1\n",
      "Correct: 1644\n",
      "Incorrect: 28\n",
      "Accuracy: 0.9832535885167464\n",
      "\n",
      "N = 2\n",
      "Correct: 1635\n",
      "Incorrect: 37\n",
      "Accuracy: 0.9778708133971292\n",
      "\n",
      "N = 3\n",
      "Correct: 1610\n",
      "Incorrect: 62\n",
      "Accuracy: 0.9629186602870813\n",
      "\n",
      "N = 1\n",
      "Precision: 0.9650655021834061\n",
      "Recall: 0.91701244813278\n",
      "\n",
      "N = 2\n",
      "Precision: 0.9678899082568807\n",
      "Recall: 0.8755186721991701\n",
      "\n",
      "N = 3\n",
      "Precision: 0.994475138121547\n",
      "Recall: 0.7468879668049793\n",
      "\n",
      "N = 1\n",
      "F1 Score: 0.9404255319148936\n",
      "\n",
      "N = 2\n",
      "F1 Score: 0.9193899782135075\n",
      "\n",
      "N = 3\n",
      "F1 Score: 0.8530805687203791\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_sets = []\n",
    "for n in range(1, 4):\n",
    "    test_set_copy = test_set.copy()\n",
    "    test_set_copy[\"predicted\"] = test_set_copy[\"SMS\"].apply(classify_test_set, n=n)\n",
    "    test_sets.append(test_set_copy)\n",
    "\n",
    "# Calculate the accuracy\n",
    "correct = [0] * 3\n",
    "total = test_set.shape[0]\n",
    "\n",
    "for n in range(1, 4):\n",
    "    for row in test_sets[n - 1].iterrows():\n",
    "        row = row[1]\n",
    "        if row[\"Label\"] == row[\"predicted\"]:\n",
    "            correct[n - 1] += 1\n",
    "                \n",
    "    print(\"N =\", n)\n",
    "    print(\"Correct:\", correct[n - 1])\n",
    "    print(\"Incorrect:\", total - correct[n - 1])\n",
    "    print(\"Accuracy:\", correct[n - 1] / total)\n",
    "    print()\n",
    "\n",
    "# Calcuate precision and recall\n",
    "true_positives = [0] * 3\n",
    "true_negatives = [0] * 3\n",
    "false_positives = [0] * 3\n",
    "false_negatives = [0] * 3\n",
    "\n",
    "for n in range(1, 4):\n",
    "    true_positives[n - 1] = len(test_sets[n - 1][(test_sets[n - 1][\"Label\"] == \"spam\") & (test_sets[n - 1][\"predicted\"] == \"spam\")])\n",
    "    true_negatives[n - 1] = len(test_sets[n - 1][(test_sets[n - 1][\"Label\"] == \"ham\") & (test_sets[n - 1][\"predicted\"] == \"ham\")])\n",
    "    false_positives[n - 1] = len(test_sets[n - 1][(test_sets[n - 1][\"Label\"] == \"ham\") & (test_sets[n - 1][\"predicted\"] == \"spam\")])\n",
    "    false_negatives[n - 1] = len(test_sets[n - 1][(test_sets[n - 1][\"Label\"] == \"spam\") & (test_sets[n - 1][\"predicted\"] == \"ham\")])\n",
    "\n",
    "precision = [0] * 3\n",
    "recall = [0] * 3\n",
    "\n",
    "for n in range(1, 4):\n",
    "    precision[n - 1] = true_positives[n - 1] / (true_positives[n - 1] + false_positives[n - 1]) # true positives / total predicted positives\n",
    "    recall[n - 1] = true_positives[n - 1] / (true_positives[n - 1] + false_negatives[n - 1]) # true positives / total actual positives\n",
    "\n",
    "    print(\"N =\", n)\n",
    "    print(\"Precision:\", precision[n - 1])\n",
    "    print(\"Recall:\", recall[n - 1])\n",
    "    print()\n",
    "\n",
    "# Calculate the F1 score\n",
    "f1 = [0] * 3\n",
    "\n",
    "for n in range(1, 4):\n",
    "    f1[n - 1] = 2 * (precision[n - 1] * recall[n - 1]) / (precision[n - 1] + recall[n - 1])\n",
    "\n",
    "    print(\"N =\", n)\n",
    "    print(\"F1 Score:\", f1[n - 1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600badc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
