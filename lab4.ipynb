{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77d98a4e-9418-4397-8b7a-8088621543bc",
   "metadata": {},
   "source": [
    "# Lista 4\n",
    "\n",
    "## Uczenie maszynowe i sztuczna inteligencja\n",
    "\n",
    "## Wstęp\n",
    "Na tych zajęciach przejdziemy już do wykorzystywania bardziej zaawansowanych funkcji *PyTorcha*,\n",
    "które przydają się na co dzień do konstruowania sieci neuronowych."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f12e531-8232-4f3c-bd6d-2094e1b01676",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06432e17-952e-467d-9c9e-93126c2473dc",
   "metadata": {},
   "source": [
    "# Zadanie 1 (10pt)\n",
    "\n",
    "W celu zaliczenia zadania należy uzupełnić wszystkie brakujące elementu kodu, wykonać wszystkie polecenia i wyuczyć model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0554bd7f-92f4-4bf0-a198-07060fe49bdc",
   "metadata": {},
   "source": [
    "## Cel zadania\n",
    "Celem zadania jest zapoznanie z podstawowymi funkcjami biblioteki *PyTorch* do tworzenia i uczenia sieci neuronowych a w szczególności z:\n",
    "*   Automatycznym liczeniem gradientów grafem obliczeniowym (autograd)\n",
    "*   Algorytmami off-line, on-line a także pojęciem mini-batch\n",
    "*   Algorytmami optymalizacji sieci neuronowych\n",
    "*   Liczeniem wartości funkcji straty\n",
    "*   Przekształceniami nieliniowymi\n",
    "*   Modułem `torch.nn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2f2413-f388-47b5-8c82-5ea16a90ef4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import warnings\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013099e9-afea-4473-8040-30d9d9e8198a",
   "metadata": {},
   "source": [
    "## Autograd - automatyczne liczenie gradientów\n",
    "\n",
    "Na poprzednich liście zaimplementowaliśmy funkcję wstecznej propagacji. W tym celu liczyliśmy pochodne (gradienty). Przyjrzyjmy się najpierw funkcji\n",
    "$$f(x, y) = 3x^2 + y^3$$\n",
    "Możemy tę funkcję różniczkować po dwóch zmiennych: $x$ i $y$:\n",
    "$$\\frac{\\partial f}{\\partial x} = 6x$$\n",
    "\n",
    "$$\\frac{\\partial f}{\\partial y} = 3y^2$$\n",
    "\n",
    "Jeżeli funkcję $f(x,y)$ złożymy z funkcją $g(x) = x^2$ tworząc funkcję $h(x, y) = f(g(x), y)$ to z **reguły łańcuchowej** pochodna takiej funkcji wyniesie:\n",
    "\n",
    "$$\\frac{\\partial h}{\\partial x} = \\frac{\\partial f}{\\partial g} \\frac{\\partial g}{\\partial x} = (6 (x^2)) (2 x) = 12 x^3$$\n",
    "\n",
    "Tego typu obliczenia przy wielu warstwach sieci (a więc przy wielu złożeniach funkcji liniowych i nieliniowych) stają się mocno skomplikowane. Na szczęście *PyTorch* dostarcza `torch.autograd` - silnik do automatycznego liczenia gradientów. Jak on działa? Najpierw zdefiniujmy wektory $\\mathbf x$ i $\\mathbf y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadad022-2dab-43a8-af69-f193bb540f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([0., 1., 5.], requires_grad=True)\n",
    "y = torch.tensor([8., 2., 4.], requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cef6bee-caf9-4d9b-9099-deb70bafcccb",
   "metadata": {},
   "source": [
    "Zauważ, że tworząc tensor przekazaliśmy parametr `requires_grad=True`.\n",
    " Sprawia on, że wszystkie operacje dokonane na tym tensorze są śledzone i\n",
    " tensor wynikowy będzie \"pamiętał\" przy użyciu jakiej operacji powstał. \n",
    "Policzmy naszą funkcję $f( \\mathbf x, \\mathbf y)$ dla tych tensorów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e2f49c-433c-45cd-9761-8b1a65ef2f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 3*x**2 + y**3\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faad137f-901b-4927-b5da-b6468205b183",
   "metadata": {},
   "source": [
    "Jak widać uzyskany tensor ma także zapisany parametr `grad_fn=<AddBackward0>`, czyli że powstał z dodania dwóch tensorów - dodawanie jest ostatnią operacją, która została wykonana, żeby otrzymać ten tensor. Dokonajmy propagacji wstecznej w celu policzenia gradientów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56632dcb-1ac1-4618-a381-359c67d37eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_tensors = torch.tensor([1., 1., 1.])\n",
    "z.backward(grad_tensors)\n",
    "print(x.grad == 6*x)\n",
    "print(y.grad == 3*y**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08556aa9-adc6-44b8-b30f-53921d1cf9a3",
   "metadata": {},
   "source": [
    "Nie zgadzają nam się wartości. Wynika to z kolejnej własności pytorchowego autograda - gradienty w tensorach są **akumulowane**. Jak wykonasz powyższą komórkę wielokrotnie to zobaczysz że wartości `x.grad` rosną dokładnie o $12x_i^3$ po każdym wykonaniu. Akumulacja gradientów jest przydatna w niektórych architekturach sieci neuronowych. Dlatego też trzeba *explicite* wyzerować gradienty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce002306-8285-4150-99a3-7c34fdb0b28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.grad.data.zero_()\n",
    "a = 3*(x**2)**2 + y**3\n",
    "a.backward(grad_tensors)\n",
    "print(x.grad)\n",
    "print(12*(x**3))\n",
    "assert (x.grad == 12*(x**3)).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6861b63-6747-4e87-a2c1-a85effd3dbae",
   "metadata": {},
   "source": [
    "Najpierw zacznijmy od załadowania zbioru danych i podzielenia go na zbiór uczący i testowy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b84082-3673-4549-a1f0-02eca10641b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1, stratify=y)\n",
    "\n",
    "X_train = torch.tensor(X_train).float()\n",
    "X_test = torch.tensor(X_test).float()\n",
    "y_train = torch.tensor(y_train)\n",
    "y_test = torch.tensor(y_test)\n",
    "\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d945497-9548-4c60-9dfb-4f9bffa9afee",
   "metadata": {},
   "source": [
    "## `nn.Module` oraz `CrossEntropyLoss`\n",
    "\n",
    "Na wykładzie implementowaliśmy funkcję sigmoid, inicjalizację parametrów oraz propagację w przód i wsteczną. Tym razem nie będzie trzeba tego robić, jednakże zdefiniujemy architekturę sieci przy użyciu modułu `torch.nn`.\n",
    "\n",
    "***Zaimplementuj*** klasę Perceptron - klasę dziedziczącą po `nn.Module` z jedną warstwą transformacji liniowej (Perceptrona, [`torch.nn.Linear`](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html)). Na razie ***pomiń*** transformację nieliniową (np. sigmoid). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34ad362-653b-41ef-baf0-7b565d6b4b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = ___ # Użyj nn.Linear\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f2b956-3eb5-4436-90e7-25136b39df00",
   "metadata": {},
   "source": [
    "*Uwaga*: Można także nadal używać `torch.nn` i nie wykorzystywać gotowych warstw sieci tylko samemu implementować operacje na tensorach:\n",
    "\n",
    "```\n",
    "class Perceptron(nn.Module):\n",
    "    def __init__(self, in_dim: int, out_dim: int):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(\n",
    "          torch.randn(in_dim, out_dim) / math.sqrt(in_dim)\n",
    "        )\n",
    "        self.bias = nn.Parameter(torch.zeros(out_dim))\n",
    "\n",
    "    def forward(self, xb: torch.Tensor):\n",
    "        return xb @ self.weights + self.bias\n",
    "```\n",
    "\n",
    "***Przetestuj*** poprawność swojej implementacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eac7e2a-c916-41dd-bbae-cabbfeaf96e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Perceptron()\n",
    "y_pred_0 = model(X_train[0])\n",
    "print(y_pred_0)\n",
    "\n",
    "assert isinstance(y_pred_0, torch.FloatTensor)\n",
    "assert len(y_pred_0) == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446de991-7419-4ff6-98a6-5d9c0da633ff",
   "metadata": {},
   "source": [
    "Wykorzystanie `nn.Linear` nie tylko odciążyło nas z implementacji operacji na tensorach, ale także z inicjalizacji parametrów modelu - inicjalizacja parametrów jest domyślnie implementowana przez daną warstwę. Jeżeli uruchomisz powyższy kod wielokrotnie to zauważysz, że za każdym razem otrzymujesz inny tensor wyjściowy. Wynika to z tego, że początkowe parametry modelu są domyślnie **losowane**. Oznacza to, że proces uczenia będzie **niedeterministyczny** - każde uruchomienie da inny wynik parametrów, które model się nauczy.\n",
    "\n",
    "Pozostało jeszcze dodanie nieliniowej transformacji do sieci, ale nie będziemy tego robić. Dodatkowo zamiast tworzyć osobny klasyfikator na klasę, zastosujemy jeden klasyfikator. W tym celu zmieniamy funkcję kosztu. Do klasyfikacji wieloklasowej wykorzystamy funkcję **straty krzyżowej entropii** (Cross Entropy Loss).\n",
    "\n",
    "$$ \\text{loss} = -\\frac{1}{N}\\sum_{i}^{N} \\log( \\text{softmax} (x_{i}){y_{i}}), $$\n",
    "gdzie $N$ oznacza liczbę przypadków, $x_{i}$ wyjście z ostatniej warstwy $i$-tej instancji, $y_{i}$ klasę $i$-tej instancji.\n",
    "\n",
    "**Softmax** jest przekształceniem nielinowym powszechnie używanym jako ostatnia warstwa sieci neuronowej służącej do klasyfikacji. Jej mocną stroną jest to, że suma wszystkich elementów tensora będących na jej wyjściu wynosi $1$. Dzięki temu możemy wyjście sieci interpretować jako przypisanie prawdopodbieństwa dla klasyfikacji dla danej próbki.\n",
    "\n",
    "Dla danego wektora $\\mathbf x = (x_1, x_2, \\ldots, x_i, \\ldots, x_C)$ funkcja Softmax jest zdefiniowana jako:\n",
    "$$\\text{softmax}(x_{i}) = \\frac{\\exp(x_{i})}{\\sum_{j}^{C} \\exp(x_{j})},$$\n",
    "gdzie $C$ oznacza liczbę klas.\n",
    "\n",
    "W tym zadaniu nie będziemy implementować tych funkcji samemu tylko wykorzystamy gotową implementację w bibliotece torch. Implementację znajdziemy w [`torch.nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html). Przyjmuje ona \"surowe\" wartości, dlatego że oblicza również funkcję **LogSoftmax**. Alternatywnie możemy nałożyć funkcję aktywacji LogSoftmax z modułu [`torch.nn.LogSoftmax`](https://pytorch.org/docs/stable/generated/torch.nn.LogSoftmax.html) i obliczyć negatywny logarytm funkcji wiarygodności (ang. *negative log likelihood*) [`torch.nn.NLLLoss`](https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html#torch.nn.NLLLoss). `torch.nn.NLLLoss` nie wykonuje operacji logarytmowania tylko oczekuje zlogarytmowanego wejścia.\n",
    "\n",
    "**LogSoftmax** wykorzystany jest tutaj nieprzypadkowo. Funkcja softmax w oryginalnej postaci nie jest odporna na wystąpienie niestabilności numerycznych. W przypadku liczenia entropii krzyżowej możemy wykorzystać skalę logarytmiczną do przeprowadzenia operacji. Dzięki przeniesieniu obliczania logarytmu do funkcji Softmax możemy zastąpić dzielenie na różnicę logarytmów, czyli zamiast powyższej definicji funkcja LogSoftmax przyjmuję następującą postać:\n",
    "\n",
    "$$\\text{logsoftmax}(x_{i}) = x_{i} - \\log \\bigg({\\sum_{j}^{C} \\exp(x_{j})}\\bigg)$$\n",
    "\n",
    "Dodatkowo stosowany jest także trik polegający na zastąpieniu operacji $\\log \\bigg({\\sum_{j}^{C} \\exp(x_{j})}\\bigg)$ operacją **LogSumExp**, zdefiniowaną jako\n",
    "\n",
    "$$\\text{logsumexp}(\\mathbf x) = \\max(\\mathbf x) + \\log \\bigg({\\sum_{j}^{C} \\exp(x_{j} - \\max(\\mathbf x))}\\bigg).$$\n",
    "\n",
    "Pozwala to pozbyć się dużych wartości $x_{j}$ podczas obliczania $\\exp$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c448c2-e15e-48e1-b302-9f9e35a10dfd",
   "metadata": {},
   "source": [
    "## Algorytmy online i offline (`DataLoader`)\n",
    "\n",
    "Na poprzednich listach implementowaliśmy **algorytm offline** (alternatywnie batchowy lub deterministyczny, ang. *offline*, *batch*, *deterministic*) tzn. taki, który przetwarza od razu wszystkie dane. Jednakże implementując sieci neuronowe tworzymy często algorytmy **online** (alternatywnie stochastyczne, ang. *online*, *stochastic*), które przetwarzają dane w \"kawałkach\" lub wręcz mogą dostawać je \"na bieżąco\" bez konieczności posiadania wszystkich danych przed uruchomieniem algorytmu. Są różne powody, dla których tak się robi, ale najczęściej jest tak, że przy głębszych architekturach i bardziej złożonych obiektach (np. obrazach) byłoby fizycznie niemożliwe pomieścić te wszystkie dane w pamięci RAM lub VRAM (RAM na GPU) wraz z parametrami modelu.\n",
    "\n",
    "Liczbę próbek w algorytmach stochastycznych w sieciach neuronowych określa się jako **minibatch size** lub po prostu **batch size**. Przy czym określenie *batch size* nie odnosi się tutaj do algorytmów batchowych (operujących na całym zbiorze danych), tylko do algorytmów online/minibatch. Po prostu *batch size* jest określeniem krótszym (ale mniej poprawnym) niż *minibatch size*, stąd też powszechnie używa się tego pierwszego. Z tego też powodu czasami niektórzy używają określenia *batch* na *minibatch* - warto mieć to na uwadze przy komunikowaniu się z innymi osobami.\n",
    "\n",
    "Do zaimplementowania minibatchy wykorzystamy [`torch.utils.data.DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader).\n",
    "\n",
    "***Zaimplementuj*** funkcję `to_dataloader`, która `X_train` i `y_train` oraz `X_test` i `y_test` umieści w dwóch osobnych instancjach klasy `DataLoader` z wielkością minibatacha równą `batch_size`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90161e0-65a8-4e9f-891c-7abe57373b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataloader(\n",
    "    X_train: torch.Tensor, \n",
    "    y_train: torch.Tensor, \n",
    "    X_test: torch.Tensor, \n",
    "    y_test: torch.Tensor, \n",
    "    batch_size: int = 32\n",
    ") -> Tuple[DataLoader, DataLoader]:\n",
    "    train_ds = TensorDataset(___, ___, shuffle=True)\n",
    "    train_dl = DataLoader(___, batch_size=___)\n",
    "\n",
    "    test_ds = TensorDataset(___, ___)\n",
    "    test_dl = DataLoader(___, batch_size=___)\n",
    "\n",
    "    return train_dl, test_dl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811672c8-ce27-4562-b68b-0abab8c9649f",
   "metadata": {},
   "source": [
    "***Przetestuj*** implementację"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5209c867-df3f-4603-9cc4-51b4a4685f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = to_dataloader(\n",
    "    X_train=X_train,  y_train=y_train, \n",
    "    X_test=X_test, y_test=y_test, \n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "for sample in test_loader:\n",
    "    print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfec7bdb-1fc7-4190-a43d-a7ee0f2d3d2a",
   "metadata": {},
   "source": [
    "## Ewaluacja modelu - metryki\n",
    "\n",
    "_**Zaimplementuj**_ funkcję `validate`, które dla danego modelu, funkcji straty i loadera zwróci średnią wartość funkcji straty oraz dokładność (ang. _accuracy_) dla danych z `dataloader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0370bf6-9b05-400c-b047-dee6a761c5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_correct(\n",
    "    y_pred: torch.Tensor, y_true: torch.Tensor\n",
    ") -> torch.Tensor:\n",
    "    preds = torch.argmax(y_pred, dim=1)\n",
    "    return (___ == ___).float().sum()\n",
    "\n",
    "def validate(\n",
    "    model: nn.Module, \n",
    "    loss_fn: torch.nn.CrossEntropyLoss, \n",
    "    dataloader: DataLoader\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    all = 0\n",
    "    for X_batch, y_batch in dataloader:\n",
    "        y_pred = ___\n",
    "        all += len(y_pred)\n",
    "        loss += len(y_pred) * loss_fn(y_pred, y_batch)\n",
    "        correct += count_correct(y_pred, y_batch)\n",
    "    return loss / all, correct / all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a02dde5-5895-4fb8-bf84-0b8e060e241c",
   "metadata": {},
   "source": [
    "***Przetestuj*** swoją implementację"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04236f5f-b478-4d19-92f7-36988cd8c337",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "val_train, acc_train = validate(model, loss_fn, test_loader)\n",
    "print(val_train, acc_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10821c44-a8f5-4e03-9f42-0c409f3b57f4",
   "metadata": {},
   "source": [
    "## Uczenie\n",
    "\n",
    "Przed uzupełnieniem poniżej implementacji została nam jeszcze jedna istotna kwestia do poruszenia. Otóż do tej pory aktualizację parametrów dokonywaliśmy wg prostej formuły - mnożyliśmy gradienty przez współczynnik uczenia (ang. *learning rate*) i odejmowaliśmy od parametrów. Jednakże do uczenia sieci neuronowych stosujemy często optymalizatory (ang. *optimiser*), które mogą implementować różne podejścia do uaktualniania parametrów modelu. Wykorzystamy tutaj algorytm **Adam** (ang. *adaptive moment estimation*), który dostosowuje współczynnik uczenia do poszczególnych parametrów i jest często optymizatorem pierwszego wyboru.\n",
    "\n",
    "***Uzupełnij i przetestuj*** poniższą implementację uczenia modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcb604a-d654-4c4c-b0e5-9879079409f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(\n",
    "    model: nn.Module, optimiser: optim.Optimizer, \n",
    "    loss_fn: torch.nn.CrossEntropyLoss, train_dl: DataLoader, \n",
    "    val_dl: DataLoader, epochs: int, \n",
    "    print_metrics: str = True\n",
    "):\n",
    "    for epoch in range(epochs):\n",
    "        for X_batch, y_batch in train_dl:\n",
    "            y_pred = model(___) # Uzyskanie pseudoprawdopodobieństw dla próbek z minibatcha\n",
    "            loss = ___ # Policzenie funkcji straty\n",
    "\n",
    "            loss.___() # Wsteczna propagacja z wyniku funkcji straty - policzenie gradientów i zapisanie ich w tensorach (parametrach)\n",
    "            optimiser.step() # Aktualizacja parametrów modelu przez optymalizator na podstawie gradientów zapisanych w tensorach (parametrach) oraz lr\n",
    "            optimiser.zero_grad() # Wyzerowanie gradientów w modelu, alternatywnie można wywołać percepron.zero_grad()\n",
    "        \n",
    "        if print_metrics: \n",
    "            model.eval() # Przełączenie na tryb ewaluacji modelu - istotne dla takich warstw jak Dropout czy BatchNorm\n",
    "            with torch.no_grad():  # Wstrzymujemy przeliczanie i śledzenie gradientów dla tensorów - w procesie ewaluacji modelu nie chcemy zmian w gradientach\n",
    "                train_loss, train_acc = validate(___)\n",
    "                val_loss, val_acc = validate(___)\n",
    "                print(\n",
    "                    f\"Epoch {epoch}: \"\n",
    "                    f\"train loss = {train_loss:.3f} (acc: {train_acc:.3f}), \"\n",
    "                    f\"validation loss = {val_loss:.3f} (acc: {val_acc:.3f})\"\n",
    "                )       \n",
    "      \n",
    "    model.eval() # Przełączenie na tryb ewaluacji modelu - istotne dla takich warstw jak Dropuot czy BatchNorm\n",
    "\n",
    "train_dl, test_dl = to_dataloader(\n",
    "    X_train=X_train, \n",
    "    y_train=y_train, \n",
    "    X_test=X_test, \n",
    "    y_test=y_test, \n",
    "    batch_size=32\n",
    ")\n",
    "perceptron = Perceptron()\n",
    "optimiser = optim.Adam(perceptron.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "fit(\n",
    "    model=perceptron, optimiser=optimiser, loss_fn=loss_fn, \n",
    "    train_dl=train_dl, val_dl=test_dl, epochs=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfd8bf2-1f83-4f08-9c01-4883b1c51f46",
   "metadata": {},
   "source": [
    "***Uzupełnij*** funkcję `fit`, aby ta mogła logować metryki (*loss*, *accuracy*) per epokę. Po zebraniu historii uczenia ***przedstaw*** następujące wykresy:\n",
    "- Wykres wartości funkcji kosztu w zależności od epoki uczenia dla zbioru uczącego i testowego\n",
    "- Wykres wartości metryki *accuracy* w zależności od epoki uczenia dla zbioru uczącego i testowego \n",
    "\n",
    "Metryki dla obu zbiorów przedstaw na jednym wykresie jako serie. ***Uzupełnij*** etykiety osi i tytuły wykresów."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22262df9-7817-4963-95fb-b3db61bd8c8c",
   "metadata": {},
   "source": [
    "***Popraw*** model, tak aby otrzymać dokładność na zbiorze testowym wynoszącą co najmniej 90%. W tym celu dobierz odpowiedni współczynnik uczenia i liczbę epok. \n",
    "Do porównania badanych hiperparametrów użyj zbioru walidacyjnego. Podziel zbiór testowy na dwie równe części, jeden który będzie służyć do walidacji hiperparametrów, a drugi, który będzie służył do ewaluacji znalezionej najlepszej pary hiperparametrów. W tym celu możesz wykorzystać funkcję [`torch.utils.data.random_split`](https://pytorch.org/docs/stable/data.html#torch.utils.data.random_split) z ustawionym parametrem `generator=torch.Generator().manual_seed(1)`. Przedstaw również wykresy o których mowa w punkcie powyżej tym razem z uwzględniam trzech zbiorów [(uczącego, walidacyjnego i testowego)](https://en.wikipedia.org/wiki/Training,_validation,_and_test_data_sets)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba14c8b1-08df-4b6b-81dc-5870ba924ef0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97883efa-a70d-423c-a576-4a5def84cf5f",
   "metadata": {},
   "source": [
    "# Zadanie 2 (15pt)\n",
    "\n",
    "W celu zaliczenia zadania należy uzupełnić wszystkie brakujące elementu kodu, wykonać wszystkie polecenia i wyuczyć model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f74b07-9d50-434d-8ed5-896aa0878405",
   "metadata": {},
   "source": [
    "## Cel zadania\n",
    "\n",
    "Celem zadania jest zapoznanie z:\n",
    "*   Wielowarstwowymi sieciami neuronowymi (MLP)\n",
    "*   Podstawami przetwarzania obrazów (ang. Computer Vision)\n",
    "*   Metodami regularyzacji sieci neuronowych\n",
    "*   Techniką wczesnego zatrzymania uczenia\n",
    "*   Tensorboardem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd9abe4-32f6-4e43-9cc2-ae1490139826",
   "metadata": {},
   "source": [
    "# Zbiór danych do klasyfikacji obrazów\n",
    "\n",
    "W ramach zadania klasyfikacji obrazów wykorzystamy zbiór [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). Zbiór danych składa się z 70.000 obrazów o wymiarach 28x28 pikseli przedstawiających różne typy odzieży w skali szarości. Podobnie jak [MNIST](https://en.wikipedia.org/wiki/MNIST_database), w zbiorze występuje 10 klas.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a828de8-4631-4c60-ba22-e1153bafebe6",
   "metadata": {},
   "source": [
    "### Wczytanie danych\n",
    "Do wczytania zbioru danych możemy wykorzystać [`torchvision`](https://pytorch.org/vision/stable/index.html), który zawiera popularne zbiory danych, modele i transformacje danych z dziedziny przetwarzania obrazów (ang. *computer vision*). \n",
    "\n",
    "Oryginalne dane są zapisane w postaci liczb całkowitych z zakresu 0-255 w postaci [obrazu PIL](https://pillow.readthedocs.io/en/stable/reference/Image.html). Do przeskalowania danych wykorzystamy transformację [`torchvision.transforms.ToTensor`](https://pytorch.org/vision/stable/transforms.html#torchvision.transforms.ToTensor). Transformacje danych możemy przekazywać do loadera zbioru danych z `torchvision`. Można przekazać zarówno pojedynczą operację transformacji lub złożyć kilka operacji za pomocą [`torchvision.transforms.Compose`](https://pytorch.org/vision/stable/transforms.html#torchvision.transforms.Compose)\n",
    "\n",
    "**Uwaga** \n",
    "Operacje transform są realizowane w \"locie\" w momencie wywołania `__getitem__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba4dda3-5e86-4d6f-9d70-f354d39b1f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from torchvision.datasets import FashionMNIST \n",
    "from torchvision import transforms\n",
    "\n",
    "path = './data'\n",
    "os.makedirs(path, exist_ok=True)\n",
    "\n",
    "train_data = FashionMNIST(\n",
    "    root=path, \n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")\n",
    "test_data = FashionMNIST(\n",
    "    root=path, \n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cd16b6-6071-4232-b6a7-6430033d5d3a",
   "metadata": {},
   "source": [
    "# Wizualizacja danych\n",
    "\n",
    "W odróżnieniu od poprzednich zadań, gdzie ręcznie rysowaliśmy krzywe uczenia i metryki, tym razem wykorzystamy narzędzie do wizualizacji [`tensorboard`](https://www.tensorflow.org/tensorboard). O ile oryginalnie Tensorboard był rozwijany dla Tensorflowa, to i tak możemy wykorzystać w PyTorchu. Funkcje pomocnicze znajdują się w module [`torch.utils.tensorboard`](https://pytorch.org/docs/stable/tensorboard.html). \n",
    "\n",
    "Tensorboard bazuje na logach, które umieszczamy w odpowiednim folderze. Dlatego najpierw zaczniemy od stworzenia takich logów, a dopiero w późniejszym etapie uruchomimy tensorboarda. Zapisywanie logów odbywa się za pomocą klasy [`SummaryWriter`](https://pytorch.org/docs/stable/tensorboard.html?highlight=summarywriter#torch.utils.tensorboard.writer.SummaryWriter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3346cf-92ce-4a94-aa8d-13e0b8952fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "log_dir = './logs/'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "writer = SummaryWriter(log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074e0dce-1020-4047-be13-2553e8d6a76b",
   "metadata": {},
   "source": [
    "Wyświetlmy teraz kilka obrazów ze zbioru uczącego. Do wyświetlenia siatki zdjęć wykorzystamy funkcję pomocniczą [`torchvision.utils.make_grid`](https://pytorch.org/vision/stable/utils.html#torchvision.utils.make_grid). Do elementów zbioru uczącego, bez nałożonej transformacji, możemy się odwołać za pomocą obiektu `data`. Metoda `make_grid` oczekuje danych w formacie `Batch x Liczba Kanałów x Wysokość x Szerokość`, dlatego musimy dostosować\n",
    " odpowiednio wejście. Pełny kod zdefiniowano poniżej. Następnie \n",
    "przekazujemy utworzony w taki sposób grid, do utworzonej wcześniej \n",
    "instancji klasy `SummaryWriter` za pomocą metody `add_image`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7ffa72-c4a7-4700-abde-c9ffbedbbd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "images_to_plot = 64\n",
    "img_grid = torchvision.utils.make_grid(\n",
    "    train_data.data[0:images_to_plot].reshape(images_to_plot, 1, 28, 28)\n",
    ")\n",
    "\n",
    "writer.add_image('Train data sample', img_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17efaaea-232b-48f9-a9ba-81e029c536a3",
   "metadata": {},
   "source": [
    "Logi nie są już w tym momencie puste, a więc możemy uruchomić Tensorboarda. Tensorboard w środowisku Jupytera uruchamiamy za pomocą komend `%load_ext tensorboard` i `% tensorboard --logdir ./logs`. Można też po uruchomieniu zobaczyć tensorboard w osobnej zakładce (zazwyczaj http://localhost:6006 lub dalsze porty 6007, 6008, ...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d4a3f6-159c-4ed6-9656-b0c2fa8c3346",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir $log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36f66b8-7195-4ad0-bf56-32cc03e6c1ac",
   "metadata": {},
   "source": [
    "# Implementacja architektury MLP\n",
    "\n",
    "Teraz przejdziemy do implementacji architektury wielowarstwowego perceptrona (ang. *multilayer perceptron*, *MLP*). \n",
    "Do zdefiniowania architektury wykorzystaj moduł `torch.nn.Sequential`, przekazując obiekt `OrderDict` zawierający nazwę i warstwy. \n",
    "\n",
    "Przykład\n",
    "\n",
    "```python\n",
    "nn.Sequential(OrderedDict([\n",
    "    ('dense1', nn.Linear(20, 10)),\n",
    "    ('relu1', nn.ReLU()),\n",
    "]))\n",
    "```\n",
    "\n",
    "\n",
    "***Zaimplementuj*** podaną architekturę sieci neuronowej\n",
    "\n",
    "| Nazwa warstwy | Opis |\n",
    "| --- | --- |\n",
    "| `flatten` | Spłaszczenie obrazu z wymiaru **28x28** na wymiar **784** |\n",
    "| `dense1` | Warstwa w pełni połączona z **256** neuronami |\n",
    "| `relu1` | Funkcja aktywacji **ReLU** |\n",
    "| `dense2` | Warstwa w pełni połączona z **128** neuronami |\n",
    "| `relu2` | Funkcja aktywacji **ReLU** |\n",
    "| `dense3` | Warstwa w pełni połączona z **10** neuronami |\n",
    "\n",
    "\n",
    "*Metoda inicjalizacji wag i biasów*: domyślna dla warstwy `torch.nn.Linear` (Rozkład jednostajny z zakresem wartości $\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})$, gdzie $k = \\frac{1}{\\text{in\\_features}}$)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e35aea-0098-4811-b4de-b88a664594b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class MLP(nn.Module): \n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    self.net = nn.Sequential(\n",
    "        ____\n",
    "    )\n",
    "  \n",
    "  def forward(self, x: torch.Tensor):\n",
    "      ____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066f6a2f-fbc2-4f00-81aa-c492610d8967",
   "metadata": {},
   "source": [
    "Mając zdefiniowaną architekturę i wczytany zbiór danych możemy teraz \n",
    "wyświetlić naszą architekturę w postaci grafu obliczeniowego w \n",
    "Tensorboardzie. W tym celu wykorzystamy poniższy kod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cbc670-4542-49d0-9f3b-e0cfb3851e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP()\n",
    "\n",
    "writer.add_graph(mlp, input_to_model=train_data[0][0])\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2038ab-7561-4145-b4ad-c138f3e35d51",
   "metadata": {},
   "source": [
    "Tym razem wykorzystany podział zbioru na trzy części: [treningowy, walidacyjny (valid) i testowy](https://en.wikipedia.org/wiki/Training,_validation,_and_test_data_sets). Z tą różnicą, że zbiór testowy pozostawimy bez zmian, aby mieć możliwość porównania się do wyników [innych klasyfikatorow](http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/).   \n",
    "\n",
    "***Zaprogramuj*** nowy podział danych:\n",
    "-  Zbiór treningowy podziel na dwie części:\n",
    "   - zbiór treningowy/uczący zawierający 54.000 elementy,\n",
    "   - zbiór walidacyjny zawierający 6.000 elementów.\n",
    "- Zbiór testowy ma pozostać w oryginalnej formie.\n",
    "- Zachowaj oryginalne proporcje klas w nowo utworzonych zbiorach, tj. dokonaj stratyfikacji. Operację wykonaj na indeksach i utwórz podzbiory używając klasy `torch.utils.data.Subset`. Ustaw `random_state` podziału na $1$.\n",
    "- Utwórz instancje klasy `DataLoader` dla wszystkich części zbiorów. Ustaw wartość parametru `batch_size` na $128$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c09525-5e0d-4600-8109-60ae22323040",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import  DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_train_data(\n",
    "    train_data: torchvision.datasets.FashionMNIST\n",
    ") -> Tuple[Subset, Subset]:\n",
    "    train_idx, valid_idx = train_test_split(\n",
    "        ____,\n",
    "        test_size=___, stratify=____,\n",
    "        random_state=____\n",
    "    )\n",
    "    train = Subset(____)\n",
    "    valid = Subset(____)\n",
    "    return train, valid\n",
    "\n",
    "train, valid = split_train_data(train_data)\n",
    "\n",
    "train_loader = DataLoader(____)\n",
    "valid_loader = DataLoader(____)\n",
    "test_loader = DataLoader(____)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e995c40d-607f-4ba2-acdf-8d359595658d",
   "metadata": {},
   "source": [
    "## Inicjalizacja parametrów sieci\n",
    "Domyślne parametry (w tym metoda inicjalizacji wag / biasów) w bibliotece `PyTorch` są dobrane tak, aby dla różnych zadań i architektur dawały optymalne wyniki. W niektórych przypadkach dobranie odpowiedniej metody inicjalizacji wag i biasów do zastosowanej architektury, może usprawnić proces uczenia, przez co poprawić osiągi modelu. Poniżej przedstawiono przykład zastąpienia domyślnej metody inicjalizacji na inicjalizację parametrów z rozkładu normalnego dla pojedynczej warstwy.\n",
    "\n",
    "```python\n",
    "from torch import nn\n",
    "\n",
    "layer = nn.Linear(100, 10)\n",
    "nn.init.normal_(layer.weight, mean=0.0, std=1.0)\n",
    "```\n",
    "Alternatywnie, możemy zmienić inicjalizacje dla kilku warstw, wykorzystując metodę `apply`.\n",
    "\n",
    "```python\n",
    "net = nn.Sequential(\n",
    "      nn.Linear(100, 10),\n",
    "      nn.Linear(10, 1)\n",
    ")\n",
    "\n",
    "def init_layer_params(layer: nn.modules.Module):\n",
    "  if isinstance(layer, nn.Linear):\n",
    "    nn.init.normal_(layer.weight, mean=0.0, std=1.0)\n",
    "    nn.init.normal_(layer.bias, mean=0.0, std=1.0)\n",
    "\n",
    "net.apply(init_layer_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18873aff-8542-4d71-8172-41651e6bd0a9",
   "metadata": {},
   "source": [
    "## Generowanie wykresów w Tensorboardzie\n",
    "\n",
    "Logowanie metryk do Tensorboarda odbywa się z wykorzystaniem metody `writer.add_scalar`. Wartości dodajemy pojedynczo. Poniżej przedstawiono przekazanie wartości funkcji straty z kolejnych epok do writera.\n",
    "\n",
    "```python\n",
    "train_loss_values = [0.78, 0.65, 0.5]\n",
    "for epoch_id, train_loss in enumerate(train_loss_values):\n",
    "  writer.add_scalar(\n",
    "    tag='training loss', \n",
    "    scalar_value=train_loss, \n",
    "    global_step=epoch_id+1\n",
    "  )\n",
    "```\n",
    "Nie musimy przekazać wartości osobno dla train i test można umieścić je w jednym obiekcie. Odbywa się to za pomocą metody `writer.add_scalars`. Przykładowe wywołanie dla wartości funkcji straty ze zbioru treningowego i walidacyjnego.\n",
    "\n",
    "```python\n",
    "train_loss_values = [0.78, 0.65, 0.5]\n",
    "valid_loss_values = [0.96, 0.78, 0.79]\n",
    "\n",
    "for epoch_id, (train_loss, valid_loss) in (\n",
    "  enumerate(zip(train_loss_values, valid_loss_values))\n",
    "):\n",
    "    print(train_loss, valid_loss)\n",
    "    writer.add_scalars(\n",
    "      main_tag='loss', \n",
    "      tag_scalar_dict={\n",
    "        'train': train_loss,\n",
    "        'valid': valid_loss\n",
    "      }, \n",
    "      global_step=epoch_id+1\n",
    "    )\n",
    "```\n",
    "\n",
    "Wykresy do Tensorboard dodawane są za pomocą metody `add_figure`. Poniżej zaprezentowano przykład dodania macierzy pomyłek do Tensorboarda.\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "cm = confusion_matrix(\n",
    "    y_true=[0, 1, 0, 0], \n",
    "    y_pred=[1, 1, 1, 0]\n",
    ")\n",
    "sns.heatmap(cm, annot=True, figure=fig)\n",
    "writer.add_figure(tag='Confusion matrix', figure=fig)\n",
    "```\n",
    "\n",
    "Można wykorzystując funkcję `fit` z poprzedniego zadania ***dodaj***:\n",
    "- Generowanie wykresów krzywej uczenia dla Tensorboarda w zależności od epoki dla zbioru uczącego oraz walidacyjnego\n",
    "- Generowanie wykresów dokładności (ang. *accuracy*) dla Tensorboarda w zależności od epoki dla zbioru uczącego oraz walidacyjnego\n",
    "- Macierz pomyłek dla zbioru testowego po zakończeniu uczenia\n",
    "\n",
    "***Przeprowadź uczenie*** modelu sieci wykorzystując następujące hiperparametry uczenia: \n",
    "\n",
    "- Funkcja straty: ***Entropia krzyżowa***\n",
    "- Wielkość paczki (*min-batch*): ***128***  \n",
    "- Optymalizator: ***Adam*** \n",
    "- Współczynnik uczenia: ***0.01***  \n",
    "- Liczba epok: ***50*** \n",
    "\n",
    "***Dokonaj ewaluacji*** modelu po zakończeniu uczenia na zbiorze testowym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de44aae-b820-4ac1-8d1b-042bb43543e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TUTAJ KOD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224bd478-7760-4311-be2d-c9de1499e9aa",
   "metadata": {},
   "source": [
    "# [Wczesne zatrzymywanie uczenia (ang. *early stopping*)](https://en.wikipedia.org/wiki/Early_stopping)\n",
    "\n",
    "Jak można zauważyć jakość klasyfikacji na zbiorze walidacyjnym po kilkunastu epokach zaczyna oscylować w takim samym zakresie wartości. Możemy wykorzystać technikę wczesnego zatrzymania, w momencie kiedy funkcja straty na zbiorze walidacyjnym przestaje maleć, zatrzymywany jest cały proces. Liczba epok po których nie dochodzi do poprawy wartości funkcji kosztu, i zatrzymywany jest proces uczenia, jest kontrolowany hiperparametrem cierpliwości (ang. *patience*).\n",
    "\n",
    "Do zaimplementowania tej techniki potrzebne nam będzie zapisywanie modelu po każdej epoce w której doszło do poprawy jakości modelu. W tym celu używamy metody `torch.save`, który zapisuje zadany mu obiekt w postaci pythonowego pickla. W bibliotece `PyTorch` dostęp do wyuczalnych parametrów mamy za pomocą `state_dict`. `state_dict` jest to pythonowy słownik, który mapuje każdą warstwę do tensora jej parametrów. Jeżeli chcemy użyć modelu do inferencji wystarczy, że zapiszemy wyłącznie parametry modelu. W przypadku kiedy chcemy mieć możliwość douczenia modelu w późniejszym momencie musimy również zapisać `state_dict` z wykorzystanego optymalizatora. Do nas należy decyzja co chcemy zapisać, więc oprócz samych parametrów warto zapisać numer epoki, wartości funkcji kosztu, hiperparametry modelu czy optymalizatora.\n",
    "\n",
    "Przykładowy kod do zapisywania modelu\n",
    "```python\n",
    "torch.save(\n",
    "    obj={\n",
    "      'epoch': epoch,\n",
    "      'loss': loss,\n",
    "      'model_state_dict': model.state_dict(),\n",
    "      'optimizer_state_dict': optimizer.state_dict(),\n",
    "      'model_args': model_args,\n",
    "      'optim_args': optim_args\n",
    "    },\n",
    "    f=output_path\n",
    ")\n",
    "```\n",
    "\n",
    " Wczytanie modelu składa się z kilku kroków:\n",
    " - Wczytujemy zapisany przez nas punkt kontrolny (ang. *checkpoint*)\n",
    " - Inicjalizujemy model i optymalizator od nowa.\n",
    " - Ładujemy obiekt `state_dict` odpowiednio do modelu i optymalizatora\n",
    "\n",
    "Przykładowy kod do wczytania modelu.\n",
    "\n",
    "```python\n",
    "checkpoint = torch.load(output_path)\n",
    "\n",
    "model = ModelCls(**checkpoint['model_args'])\n",
    "optimizer = OptimazerCls(**checkpoint['optim_args'])\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbb88de-0e6f-4651-9a51-703657d4464d",
   "metadata": {},
   "source": [
    "**Zaimplementuj technikę wczesnego zatrzymania** wraz z zapisywaniem punktów kontrolnych modelu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2891289d-b56f-4654-b216-2813bdfaf015",
   "metadata": {},
   "source": [
    "***Zastosuj*** dwie wybrane techniki regularyzacji sieci (L1, L2, Dropout). Sprawdź czy poprawiły one wyniki Twojego modelu na zbiorze testowym. Dodaj wykresy do Tensorboarda, dokonaj porównania i podsumowania wyników\n",
    "\n",
    "**UWAGA** W przypadku zastosowania metody optymalizacji `Adam` i regularyzacji `L2` należy zastosować optymalizator `AdamW`. Więcej szczegółów można znaleźć w publikacji autorów optymalizatora `AdamW` https://arxiv.org/abs/1711.05101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f531004-0209-41c7-bb6f-2b40a6ec0238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TUTAJ KOD"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
